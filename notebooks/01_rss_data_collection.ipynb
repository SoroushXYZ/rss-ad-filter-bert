{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RSS Data Collection for Advertisement Detection\n",
        "\n",
        "This notebook focuses on collecting RSS feed data from various news sources to build a dataset for training a BERT-based advertisement classifier.\n",
        "\n",
        "## Goals:\n",
        "1. Collect RSS feeds from multiple news sources\n",
        "2. Parse and clean the RSS content\n",
        "3. Identify potential advertisements vs. legitimate news content\n",
        "4. Create a labeled dataset for model training\n",
        "\n",
        "## RSS Sources to Consider:\n",
        "- Major news outlets (CNN, BBC, Reuters, etc.)\n",
        "- Tech news sites (TechCrunch, Ars Technica, etc.)\n",
        "- Business news (Bloomberg, Financial Times, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All required libraries imported successfully!\n",
            "Current working directory: /Users/soroushxyz/Documents/Dev/Python/Bert-Advertisement-Detection/rss-ad-filter-bert/notebooks\n",
            "Project structure: ['01_rss_data_collection.ipynb']\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import feedparser\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "print(\"All required libraries imported successfully!\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "print(f\"Project structure: {os.listdir('.')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Updated RSS feed sources: 77 sources\n",
            "\n",
            "Categories represented:\n",
            "- Tech News (major outlets)\n",
            "- AI/ML Research\n",
            "- Data Science\n",
            "- Cloud/Enterprise\n",
            "- Hardware/Gadgets\n",
            "- Big Tech Companies\n",
            "- Cybersecurity\n",
            "- Developer/Engineering\n"
          ]
        }
      ],
      "source": [
        "# Updated RSS feed sources - comprehensive tech news collection\n",
        "RSS_FEEDS = {\n",
        "    \"TechCrunch\": \"https://techcrunch.com/feed\",\n",
        "    \"WIRED\": \"https://www.wired.com/feed/rss\",\n",
        "    \"The Verge\": \"https://www.theverge.com/rss/index.xml\",\n",
        "    \"Ars Technica\": \"http://feeds.arstechnica.com/arstechnica/index/\",\n",
        "    \"Engadget\": \"https://www.engadget.com/rss.xml\",\n",
        "    \"Gizmodo\": \"https://gizmodo.com/rss\",\n",
        "    \"CNET News\": \"https://www.cnet.com/rss/news/\",\n",
        "    \"TechRadar\": \"https://www.techradar.com/feeds\",\n",
        "    \"Digital Trends\": \"https://www.digitaltrends.com/feed/\",\n",
        "    \"VentureBeat\": \"https://venturebeat.com/feed/\",\n",
        "    \"Recode (Vox Technology)\": \"https://www.vox.com/rss/technology/index.xml\",\n",
        "    \"GeekWire\": \"https://www.geekwire.com/feed/\",\n",
        "    \"Mashable (Tech)\": \"http://feeds.mashable.com/Mashable\",\n",
        "    \"Hacker News (Top)\": \"https://news.ycombinator.com/rss\",\n",
        "    \"TechMeme\": \"https://www.techmeme.com/feed.xml\",\n",
        "    \"Slashdot\": \"http://rss.slashdot.org/Slashdot/slashdotMain\",\n",
        "    \"Lifehacker\": \"https://lifehacker.com/rss\",\n",
        "    \"MIT Technology Review\": \"https://www.technologyreview.com/feed/\",\n",
        "    \"BBC News - Technology\": \"http://feeds.bbci.co.uk/news/technology/rss.xml\",\n",
        "    \"The Guardian - Technology\": \"https://www.theguardian.com/technology/rss\",\n",
        "    \"NY Times - Technology\": \"https://rss.nytimes.com/services/xml/rss/nyt/Technology.xml\",\n",
        "    \"Reuters Technology News\": \"http://feeds.reuters.com/reuters/technologyNews\",\n",
        "    \"CNN Technology\": \"http://rss.cnn.com/rss/cnn_tech.rss\",\n",
        "    \"Business Insider (Tech)\": \"https://www.businessinsider.com/rss\",\n",
        "    \"HuffPost Tech\": \"https://www.huffpost.com/section/technology/feed\",\n",
        "    \"ZDNet (All Topics)\": \"https://www.zdnet.com/rss.xml\",\n",
        "    \"InfoWorld\": \"https://www.infoworld.com/index.rss\",\n",
        "    \"Computerworld\": \"https://www.computerworld.com/index.rss\",\n",
        "    \"OpenAI Blog\": \"https://openai.com/news/rss.xml\",\n",
        "    \"Google AI Blog (Research)\": \"https://research.google/blog/rss/\",\n",
        "    \"DeepMind Blog\": \"https://deepmind.com/blog/feed/basic\",\n",
        "    \"BAIR (Berkeley AI Research) Blog\": \"https://bair.berkeley.edu/blog/feed.xml\",\n",
        "    \"Machine Learning Mastery\": \"https://machinelearningmastery.com/blog/feed/\",\n",
        "    \"MarkTechPost (AI News)\": \"https://marktechpost.com/feed/\",\n",
        "    \"Analytics Vidhya\": \"https://analyticsvidhya.com/feed\",\n",
        "    \"KDnuggets\": \"https://www.kdnuggets.com/feed\",\n",
        "    \"Towards Data Science\": \"https://towardsdatascience.com/feed\",\n",
        "    \"Datanami\": \"https://www.datanami.com/feed/\",\n",
        "    \"Kaggle Blog\": \"https://medium.com/feed/kaggle-blog\",\n",
        "    \"AWS News Blog\": \"https://aws.amazon.com/blogs/aws/feed/\",\n",
        "    \"All Things Distributed (AWS CTO)\": \"http://www.allthingsdistributed.com/atom.xml\",\n",
        "    \"Microsoft Azure Blog\": \"https://azure.microsoft.com/en-us/blog/feed/\",\n",
        "    \"Google Cloud Blog\": \"https://cloudblog.withgoogle.com/rss\",\n",
        "    \"CloudTech News\": \"https://cloudcomputing-news.net/feed\",\n",
        "    \"CloudTweaks\": \"https://cloudtweaks.com/feed\",\n",
        "    \"TechRepublic (Cloud)\": \"https://www.techrepublic.com/rssfeeds/topic/cloud/\",\n",
        "    \"IBM Cloud Blog\": \"https://www.ibm.com/blogs/cloud-computing/feed/\",\n",
        "    \"AnandTech\": \"https://www.anandtech.com/rss/\",\n",
        "    \"Tom's Hardware\": \"https://www.tomshardware.com/feeds/all\",\n",
        "    \"9to5Mac\": \"https://9to5mac.com/feed/\",\n",
        "    \"Android Authority\": \"https://www.androidauthority.com/feed\",\n",
        "    \"ExtremeTech\": \"https://www.extremetech.com/feed\",\n",
        "    \"NVIDIA Blog\": \"https://blogs.nvidia.com/feed/\",\n",
        "    \"Official Microsoft Blog\": \"https://blogs.microsoft.com/feed/\",\n",
        "    \"Apple Newsroom\": \"https://www.apple.com/newsroom/rss-feed.rss\",\n",
        "    \"Google (The Keyword)\": \"https://blog.google/rss/\",\n",
        "    \"Facebook Newsroom (Meta)\": \"https://about.fb.com/feed/\",\n",
        "    \"Meta Engineering Blog\": \"https://engineering.fb.com/feed/\",\n",
        "    \"Meta Research Blog\": \"https://research.facebook.com/feed/\",\n",
        "    \"Stratechery (Ben Thompson)\": \"https://stratechery.com/feed/\",\n",
        "    \"Daring Fireball\": \"https://daringfireball.net/index.xml\",\n",
        "    \"The Hacker News\": \"https://feeds.feedburner.com/TheHackersNews\",\n",
        "    \"BleepingComputer\": \"https://www.bleepingcomputer.com/feed/\",\n",
        "    \"Microsoft Security Response Center\": \"https://msrc.microsoft.com/blog/feed\",\n",
        "    \"Cloudflare Blog\": \"https://blog.cloudflare.com/rss/\",\n",
        "    \"Netflix Tech Blog\": \"https://netflixtechblog.com/rss\",\n",
        "    \"Datafloq\": \"https://datafloq.com/feed\",\n",
        "    \"Xtract.io Blog\": \"https://xtract.io/blog/feed\",\n",
        "    \"Silicon Valley Journals\": \"https://siliconvalleyjournals.com/feed\",\n",
        "    \"TechSpot\": \"https://www.techspot.com/backend.xml\",\n",
        "    \"AppleInsider\": \"https://appleinsider.com/rss/news\",\n",
        "    \"gHacks\": \"https://www.ghacks.net/feed\",\n",
        "    \"eWeek\": \"https://www.eweek.com/feed\",\n",
        "    \"Droid Life\": \"https://www.droid-life.com/feed\",\n",
        "    \"TechJuice\": \"https://www.techjuice.pk/feed\",\n",
        "    \"Developer Tech News\": \"https://developer-tech.com/feed\",\n",
        "    \"TechPlugged\": \"https://www.techplugged.com/feed\"\n",
        "}\n",
        "\n",
        "print(f\"✅ Updated RSS feed sources: {len(RSS_FEEDS)} sources\")\n",
        "print(\"\\nCategories represented:\")\n",
        "print(\"- Tech News (major outlets)\")\n",
        "print(\"- AI/ML Research\") \n",
        "print(\"- Data Science\")\n",
        "print(\"- Cloud/Enterprise\")\n",
        "print(\"- Hardware/Gadgets\")\n",
        "print(\"- Big Tech Companies\")\n",
        "print(\"- Cybersecurity\")\n",
        "print(\"- Developer/Engineering\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. **Install RSS parsing library**: We'll need `feedparser` to parse RSS feeds\n",
        "2. **Create data collection functions**: Functions to fetch and parse RSS feeds\n",
        "3. **Data cleaning**: Remove HTML tags, normalize text, handle encoding\n",
        "4. **Initial labeling**: Manual inspection to identify advertisements vs news\n",
        "5. **Data export**: Save collected data in structured format (CSV/JSON)\n",
        "\n",
        "Let's start by installing the required dependencies:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting from TechCrunch...\n",
            "Collecting from WIRED...\n",
            "Collecting from The Verge...\n",
            "Collecting from Ars Technica...\n",
            "Collecting from Engadget...\n",
            "Collecting from Gizmodo...\n",
            "Collecting from CNET News...\n",
            "Collecting from TechRadar...\n",
            "Collecting from Digital Trends...\n",
            "Collecting from VentureBeat...\n",
            "Collecting from Recode (Vox Technology)...\n",
            "Collecting from GeekWire...\n",
            "Collecting from Mashable (Tech)...\n",
            "Collecting from Hacker News (Top)...\n",
            "Collecting from TechMeme...\n",
            "Collecting from Slashdot...\n",
            "Collecting from Lifehacker...\n",
            "Collecting from MIT Technology Review...\n",
            "Collecting from BBC News - Technology...\n",
            "Collecting from The Guardian - Technology...\n",
            "Collecting from NY Times - Technology...\n",
            "Collecting from Reuters Technology News...\n",
            "Collecting from CNN Technology...\n",
            "Collecting from Business Insider (Tech)...\n",
            "Collecting from HuffPost Tech...\n",
            "Collecting from ZDNet (All Topics)...\n",
            "Collecting from InfoWorld...\n",
            "Collecting from Computerworld...\n",
            "Collecting from OpenAI Blog...\n",
            "Collecting from Google AI Blog (Research)...\n",
            "Collecting from DeepMind Blog...\n",
            "Collecting from BAIR (Berkeley AI Research) Blog...\n",
            "Collecting from Machine Learning Mastery...\n",
            "Collecting from MarkTechPost (AI News)...\n",
            "Collecting from Analytics Vidhya...\n",
            "Collecting from KDnuggets...\n",
            "Collecting from Towards Data Science...\n",
            "Collecting from Datanami...\n",
            "Collecting from Kaggle Blog...\n",
            "Collecting from AWS News Blog...\n",
            "Collecting from All Things Distributed (AWS CTO)...\n",
            "Collecting from Microsoft Azure Blog...\n",
            "Collecting from Google Cloud Blog...\n",
            "Collecting from CloudTech News...\n",
            "Collecting from CloudTweaks...\n",
            "Collecting from TechRepublic (Cloud)...\n",
            "Collecting from IBM Cloud Blog...\n",
            "Collecting from AnandTech...\n",
            "Collecting from Tom's Hardware...\n",
            "Collecting from 9to5Mac...\n",
            "Collecting from Android Authority...\n",
            "Collecting from ExtremeTech...\n",
            "Collecting from NVIDIA Blog...\n",
            "Collecting from Official Microsoft Blog...\n",
            "Collecting from Apple Newsroom...\n",
            "Collecting from Google (The Keyword)...\n",
            "Collecting from Facebook Newsroom (Meta)...\n",
            "Collecting from Meta Engineering Blog...\n",
            "Collecting from Meta Research Blog...\n",
            "Collecting from Stratechery (Ben Thompson)...\n",
            "Collecting from Daring Fireball...\n",
            "Collecting from The Hacker News...\n",
            "Collecting from BleepingComputer...\n",
            "Collecting from Microsoft Security Response Center...\n",
            "Collecting from Cloudflare Blog...\n",
            "Collecting from Netflix Tech Blog...\n",
            "Collecting from Datafloq...\n",
            "Collecting from Xtract.io Blog...\n",
            "Collecting from Silicon Valley Journals...\n",
            "Collecting from TechSpot...\n",
            "Collecting from AppleInsider...\n",
            "Collecting from gHacks...\n",
            "Collecting from eWeek...\n",
            "Collecting from Droid Life...\n",
            "Collecting from TechJuice...\n",
            "Collecting from Developer Tech News...\n",
            "Collecting from TechPlugged...\n",
            "Collected 77 feed sources\n"
          ]
        }
      ],
      "source": [
        "# RSS Feed Collection Functions\n",
        "# We'll implement the core RSS collection logic here\n",
        "\n",
        "def collect_rss_feeds(feed_urls: Dict[str, str]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Collect articles from multiple RSS feeds\n",
        "    \n",
        "    Args:\n",
        "        feed_urls: Dictionary mapping source names to RSS URLs\n",
        "        \n",
        "    Returns:\n",
        "        List of article dictionaries\n",
        "    \"\"\"\n",
        "    articles = []\n",
        "    \n",
        "    for source_name, url in feed_urls.items():\n",
        "        print(f\"Collecting from {source_name}...\")\n",
        "        # TODO: Implement RSS parsing logic\n",
        "        # For now, just placeholder structure\n",
        "        articles.append({\n",
        "            'source': source_name,\n",
        "            'url': url,\n",
        "            'status': 'pending'\n",
        "        })\n",
        "    \n",
        "    return articles\n",
        "\n",
        "# Test the function\n",
        "sample_articles = collect_rss_feeds(RSS_FEEDS)\n",
        "print(f\"Collected {len(sample_articles)} feed sources\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting articles from all RSS feeds...\n",
            "  Fetching TechCrunch...\n",
            "  ✅ Collected 20 articles from TechCrunch\n",
            "  Fetching WIRED...\n",
            "  ✅ Collected 50 articles from WIRED\n",
            "  Fetching The Verge...\n",
            "  ✅ Collected 10 articles from The Verge\n",
            "  Fetching Ars Technica...\n",
            "  ✅ Collected 20 articles from Ars Technica\n",
            "  Fetching Engadget...\n",
            "  Warning: Engadget has parsing issues\n",
            "  ✅ Collected 50 articles from Engadget\n",
            "  Fetching Gizmodo...\n",
            "  ✅ Collected 20 articles from Gizmodo\n",
            "  Fetching CNET News...\n",
            "  ✅ Collected 25 articles from CNET News\n",
            "  Fetching TechRadar...\n",
            "  Warning: TechRadar has parsing issues\n",
            "  ✅ Collected 0 articles from TechRadar\n",
            "  Fetching Digital Trends...\n",
            "  Warning: Digital Trends has parsing issues\n",
            "  ✅ Collected 0 articles from Digital Trends\n",
            "  Fetching VentureBeat...\n",
            "  Warning: VentureBeat has parsing issues\n",
            "  ✅ Collected 0 articles from VentureBeat\n",
            "  Fetching Recode (Vox Technology)...\n",
            "  ✅ Collected 10 articles from Recode (Vox Technology)\n",
            "  Fetching GeekWire...\n",
            "  ✅ Collected 35 articles from GeekWire\n",
            "  Fetching Mashable (Tech)...\n",
            "  ✅ Collected 50 articles from Mashable (Tech)\n",
            "  Fetching Hacker News (Top)...\n",
            "  ✅ Collected 30 articles from Hacker News (Top)\n",
            "  Fetching TechMeme...\n",
            "  ✅ Collected 15 articles from TechMeme\n",
            "  Fetching Slashdot...\n",
            "  ✅ Collected 15 articles from Slashdot\n",
            "  Fetching Lifehacker...\n",
            "  ✅ Collected 50 articles from Lifehacker\n",
            "  Fetching MIT Technology Review...\n",
            "  ✅ Collected 10 articles from MIT Technology Review\n",
            "  Fetching BBC News - Technology...\n",
            "  ✅ Collected 50 articles from BBC News - Technology\n",
            "  Fetching The Guardian - Technology...\n",
            "  ✅ Collected 24 articles from The Guardian - Technology\n",
            "  Fetching NY Times - Technology...\n",
            "  ✅ Collected 28 articles from NY Times - Technology\n",
            "  Fetching Reuters Technology News...\n",
            "  Warning: Reuters Technology News has parsing issues\n",
            "  ✅ Collected 0 articles from Reuters Technology News\n",
            "  Fetching CNN Technology...\n",
            "  ✅ Collected 20 articles from CNN Technology\n",
            "  Fetching Business Insider (Tech)...\n",
            "  ✅ Collected 20 articles from Business Insider (Tech)\n",
            "  Fetching HuffPost Tech...\n",
            "  ✅ Collected 1 articles from HuffPost Tech\n",
            "  Fetching ZDNet (All Topics)...\n",
            "  ✅ Collected 20 articles from ZDNet (All Topics)\n",
            "  Fetching InfoWorld...\n",
            "  Warning: InfoWorld has parsing issues\n",
            "  ✅ Collected 0 articles from InfoWorld\n",
            "  Fetching Computerworld...\n",
            "  Warning: Computerworld has parsing issues\n",
            "  ✅ Collected 0 articles from Computerworld\n",
            "  Fetching OpenAI Blog...\n",
            "  ✅ Collected 50 articles from OpenAI Blog\n",
            "  Fetching Google AI Blog (Research)...\n",
            "  ✅ Collected 50 articles from Google AI Blog (Research)\n",
            "  Fetching DeepMind Blog...\n",
            "  ✅ Collected 50 articles from DeepMind Blog\n",
            "  Fetching BAIR (Berkeley AI Research) Blog...\n",
            "  ✅ Collected 10 articles from BAIR (Berkeley AI Research) Blog\n",
            "  Fetching Machine Learning Mastery...\n",
            "  ✅ Collected 10 articles from Machine Learning Mastery\n",
            "  Fetching MarkTechPost (AI News)...\n",
            "  ✅ Collected 10 articles from MarkTechPost (AI News)\n",
            "  Fetching Analytics Vidhya...\n",
            "  ✅ Collected 10 articles from Analytics Vidhya\n",
            "  Fetching KDnuggets...\n",
            "  ✅ Collected 10 articles from KDnuggets\n",
            "  Fetching Towards Data Science...\n",
            "  ✅ Collected 20 articles from Towards Data Science\n",
            "  Fetching Datanami...\n",
            "  ✅ Collected 10 articles from Datanami\n",
            "  Fetching Kaggle Blog...\n",
            "  ✅ Collected 10 articles from Kaggle Blog\n",
            "  Fetching AWS News Blog...\n",
            "  ✅ Collected 20 articles from AWS News Blog\n",
            "  Fetching All Things Distributed (AWS CTO)...\n",
            "  ✅ Collected 10 articles from All Things Distributed (AWS CTO)\n",
            "  Fetching Microsoft Azure Blog...\n",
            "  ✅ Collected 10 articles from Microsoft Azure Blog\n",
            "  Fetching Google Cloud Blog...\n",
            "  ✅ Collected 20 articles from Google Cloud Blog\n",
            "  Fetching CloudTech News...\n",
            "  ✅ Collected 12 articles from CloudTech News\n",
            "  Fetching CloudTweaks...\n",
            "  ✅ Collected 5 articles from CloudTweaks\n",
            "  Fetching TechRepublic (Cloud)...\n",
            "  ✅ Collected 20 articles from TechRepublic (Cloud)\n",
            "  Fetching IBM Cloud Blog...\n",
            "  Warning: IBM Cloud Blog has parsing issues\n",
            "  ✅ Collected 0 articles from IBM Cloud Blog\n",
            "  Fetching AnandTech...\n",
            "  Warning: AnandTech has parsing issues\n",
            "  ✅ Collected 0 articles from AnandTech\n",
            "  Fetching Tom's Hardware...\n",
            "  ✅ Collected 50 articles from Tom's Hardware\n",
            "  Fetching 9to5Mac...\n",
            "  ✅ Collected 50 articles from 9to5Mac\n",
            "  Fetching Android Authority...\n",
            "  ✅ Collected 50 articles from Android Authority\n",
            "  Fetching ExtremeTech...\n",
            "  ✅ Collected 50 articles from ExtremeTech\n",
            "  Fetching NVIDIA Blog...\n",
            "  ✅ Collected 18 articles from NVIDIA Blog\n",
            "  Fetching Official Microsoft Blog...\n",
            "  ✅ Collected 10 articles from Official Microsoft Blog\n",
            "  Fetching Apple Newsroom...\n",
            "  ✅ Collected 20 articles from Apple Newsroom\n",
            "  Fetching Google (The Keyword)...\n",
            "  ✅ Collected 20 articles from Google (The Keyword)\n",
            "  Fetching Facebook Newsroom (Meta)...\n",
            "  ✅ Collected 10 articles from Facebook Newsroom (Meta)\n",
            "  Fetching Meta Engineering Blog...\n",
            "  ✅ Collected 9 articles from Meta Engineering Blog\n",
            "  Fetching Meta Research Blog...\n",
            "  ✅ Collected 10 articles from Meta Research Blog\n",
            "  Fetching Stratechery (Ben Thompson)...\n",
            "  ✅ Collected 10 articles from Stratechery (Ben Thompson)\n",
            "  Fetching Daring Fireball...\n",
            "  ✅ Collected 48 articles from Daring Fireball\n",
            "  Fetching The Hacker News...\n",
            "  ✅ Collected 50 articles from The Hacker News\n",
            "  Fetching BleepingComputer...\n",
            "  ✅ Collected 11 articles from BleepingComputer\n",
            "  Fetching Microsoft Security Response Center...\n",
            "  ✅ Collected 50 articles from Microsoft Security Response Center\n",
            "  Fetching Cloudflare Blog...\n",
            "  ✅ Collected 20 articles from Cloudflare Blog\n",
            "  Fetching Netflix Tech Blog...\n",
            "  Warning: Netflix Tech Blog has parsing issues\n",
            "  ✅ Collected 0 articles from Netflix Tech Blog\n",
            "  Fetching Datafloq...\n",
            "  ✅ Collected 10 articles from Datafloq\n",
            "  Fetching Xtract.io Blog...\n",
            "  ✅ Collected 10 articles from Xtract.io Blog\n",
            "  Fetching Silicon Valley Journals...\n",
            "  ✅ Collected 10 articles from Silicon Valley Journals\n",
            "  Fetching TechSpot...\n",
            "  ✅ Collected 30 articles from TechSpot\n",
            "  Fetching AppleInsider...\n",
            "  ✅ Collected 50 articles from AppleInsider\n",
            "  Fetching gHacks...\n",
            "  ✅ Collected 40 articles from gHacks\n",
            "  Fetching eWeek...\n",
            "  ✅ Collected 10 articles from eWeek\n",
            "  Fetching Droid Life...\n",
            "  ✅ Collected 15 articles from Droid Life\n",
            "  Fetching TechJuice...\n",
            "  ✅ Collected 15 articles from TechJuice\n",
            "  Fetching Developer Tech News...\n",
            "  ✅ Collected 12 articles from Developer Tech News\n",
            "  Fetching TechPlugged...\n",
            "  ✅ Collected 10 articles from TechPlugged\n",
            "\n",
            "Total articles collected: 1608\n"
          ]
        }
      ],
      "source": [
        "# Implement actual RSS parsing logic\n",
        "\n",
        "def parse_rss_feed(feed_url: str, source_name: str) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Parse a single RSS feed and extract articles\n",
        "    \n",
        "    Args:\n",
        "        feed_url: URL of the RSS feed\n",
        "        source_name: Name of the source\n",
        "        \n",
        "    Returns:\n",
        "        List of article dictionaries\n",
        "    \"\"\"\n",
        "    articles = []\n",
        "    \n",
        "    try:\n",
        "        print(f\"  Fetching {source_name}...\")\n",
        "        feed = feedparser.parse(feed_url)\n",
        "        \n",
        "        if feed.bozo:\n",
        "            print(f\"  Warning: {source_name} has parsing issues\")\n",
        "        \n",
        "        for entry in feed.entries[:50]:  # Limit to max 50 articles per feed\n",
        "            article = {\n",
        "                'source': source_name,\n",
        "                'title': entry.get('title', ''),\n",
        "                'link': entry.get('link', ''),\n",
        "                'description': entry.get('description', ''),\n",
        "                'published': entry.get('published', ''),\n",
        "                'summary': entry.get('summary', ''),\n",
        "                'tags': [tag.get('term', '') for tag in entry.get('tags', [])],\n",
        "                'feed_url': feed_url\n",
        "            }\n",
        "            articles.append(article)\n",
        "        \n",
        "        print(f\"  ✅ Collected {len(articles)} articles from {source_name}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Error fetching {source_name}: {str(e)}\")\n",
        "    \n",
        "    return articles\n",
        "\n",
        "def collect_all_feeds(feed_urls: Dict[str, str]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Collect articles from all RSS feeds\n",
        "    \n",
        "    Args:\n",
        "        feed_urls: Dictionary mapping source names to RSS URLs\n",
        "        \n",
        "    Returns:\n",
        "        List of all collected articles\n",
        "    \"\"\"\n",
        "    all_articles = []\n",
        "    \n",
        "    for source_name, url in feed_urls.items():\n",
        "        articles = parse_rss_feed(url, source_name)\n",
        "        all_articles.extend(articles)\n",
        "    \n",
        "    return all_articles\n",
        "\n",
        "# Collect from all RSS feeds\n",
        "print(\"Collecting articles from all RSS feeds...\")\n",
        "all_articles = collect_all_feeds(RSS_FEEDS)\n",
        "print(f\"\\nTotal articles collected: {len(all_articles)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame shape: (1608, 8)\n",
            "\n",
            "Columns: ['source', 'title', 'link', 'description', 'published', 'summary', 'tags', 'feed_url']\n",
            "\n",
            "First few rows:\n",
            "       source                                              title  \\\n",
            "0  TechCrunch  VCs are still hiring MBAs, but firms are start...   \n",
            "1  TechCrunch  Trump says Lachlan and Rupert Murdoch might in...   \n",
            "2  TechCrunch  Silicon Valley bets big on ‘environments’ to t...   \n",
            "3  TechCrunch  TechCrunch Mobility: The two robotaxi battlegr...   \n",
            "4  TechCrunch  Hundreds of flights delayed at Heathrow and ot...   \n",
            "\n",
            "                         published  \n",
            "0  Sun, 21 Sep 2025 22:23:40 +0000  \n",
            "1  Sun, 21 Sep 2025 19:43:34 +0000  \n",
            "2  Sun, 21 Sep 2025 19:22:56 +0000  \n",
            "3  Sun, 21 Sep 2025 16:01:00 +0000  \n",
            "4  Sun, 21 Sep 2025 15:03:26 +0000  \n",
            "\n",
            "Articles by source:\n",
            "source\n",
            "BBC News - Technology      50\n",
            "Tom's Hardware             50\n",
            "AppleInsider               50\n",
            "Engadget                   50\n",
            "WIRED                      50\n",
            "                           ..\n",
            "Microsoft Azure Blog       10\n",
            "Official Microsoft Blog    10\n",
            "Meta Engineering Blog       9\n",
            "CloudTweaks                 5\n",
            "HuffPost Tech               1\n",
            "Name: count, Length: 68, dtype: int64\n",
            "\n",
            "Sample article from TechCrunch:\n",
            "Title: VCs are still hiring MBAs, but firms are starting to need other experience more\n",
            "Description: The MBA-to-VC pipeline remains a very real thing. But that path is a little shakier than it once was, according to PitchBook reporting and new academic research....\n",
            "Published: Sun, 21 Sep 2025 22:23:40 +0000\n"
          ]
        }
      ],
      "source": [
        "# Convert to DataFrame and examine the data\n",
        "if all_articles:\n",
        "    df = pd.DataFrame(all_articles)\n",
        "    \n",
        "    print(\"DataFrame shape:\", df.shape)\n",
        "    print(\"\\nColumns:\", df.columns.tolist())\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    print(df[['source', 'title', 'published']].head())\n",
        "    \n",
        "    print(f\"\\nArticles by source:\")\n",
        "    print(df['source'].value_counts())\n",
        "    \n",
        "    # Show a sample article\n",
        "    print(f\"\\nSample article from {df.iloc[0]['source']}:\")\n",
        "    print(f\"Title: {df.iloc[0]['title']}\")\n",
        "    print(f\"Description: {df.iloc[0]['description'][:200]}...\")\n",
        "    print(f\"Published: {df.iloc[0]['published']}\")\n",
        "    \n",
        "else:\n",
        "    print(\"No articles collected. Check your RSS feed URLs.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved 1608 articles to ../data/rss_articles_20250922_000542.json\n",
            "✅ Saved collection summary to ../data/collection_summary_20250922_000542.json\n",
            "\n",
            "Articles by source:\n",
            "  BBC News - Technology: 50 articles\n",
            "  Tom's Hardware: 50 articles\n",
            "  AppleInsider: 50 articles\n",
            "  Engadget: 50 articles\n",
            "  WIRED: 50 articles\n",
            "  DeepMind Blog: 50 articles\n",
            "  The Hacker News: 50 articles\n",
            "  Google AI Blog (Research): 50 articles\n",
            "  Mashable (Tech): 50 articles\n",
            "  OpenAI Blog: 50 articles\n",
            "  ExtremeTech: 50 articles\n",
            "  Android Authority: 50 articles\n",
            "  Lifehacker: 50 articles\n",
            "  9to5Mac: 50 articles\n",
            "  Microsoft Security Response Center: 50 articles\n",
            "  Daring Fireball: 48 articles\n",
            "  gHacks: 40 articles\n",
            "  GeekWire: 35 articles\n",
            "  Hacker News (Top): 30 articles\n",
            "  TechSpot: 30 articles\n",
            "  NY Times - Technology: 28 articles\n",
            "  CNET News: 25 articles\n",
            "  The Guardian - Technology: 24 articles\n",
            "  TechRepublic (Cloud): 20 articles\n",
            "  Google Cloud Blog: 20 articles\n",
            "  Towards Data Science: 20 articles\n",
            "  Apple Newsroom: 20 articles\n",
            "  Google (The Keyword): 20 articles\n",
            "  AWS News Blog: 20 articles\n",
            "  Cloudflare Blog: 20 articles\n",
            "  TechCrunch: 20 articles\n",
            "  CNN Technology: 20 articles\n",
            "  Ars Technica: 20 articles\n",
            "  ZDNet (All Topics): 20 articles\n",
            "  Gizmodo: 20 articles\n",
            "  Business Insider (Tech): 20 articles\n",
            "  NVIDIA Blog: 18 articles\n",
            "  TechJuice: 15 articles\n",
            "  Droid Life: 15 articles\n",
            "  Slashdot: 15 articles\n",
            "  TechMeme: 15 articles\n",
            "  Developer Tech News: 12 articles\n",
            "  CloudTech News: 12 articles\n",
            "  BleepingComputer: 11 articles\n",
            "  Datafloq: 10 articles\n",
            "  Xtract.io Blog: 10 articles\n",
            "  eWeek: 10 articles\n",
            "  Meta Research Blog: 10 articles\n",
            "  Silicon Valley Journals: 10 articles\n",
            "  Stratechery (Ben Thompson): 10 articles\n",
            "  All Things Distributed (AWS CTO): 10 articles\n",
            "  Analytics Vidhya: 10 articles\n",
            "  Facebook Newsroom (Meta): 10 articles\n",
            "  The Verge: 10 articles\n",
            "  Recode (Vox Technology): 10 articles\n",
            "  MIT Technology Review: 10 articles\n",
            "  BAIR (Berkeley AI Research) Blog: 10 articles\n",
            "  Machine Learning Mastery: 10 articles\n",
            "  MarkTechPost (AI News): 10 articles\n",
            "  TechPlugged: 10 articles\n",
            "  KDnuggets: 10 articles\n",
            "  Datanami: 10 articles\n",
            "  Kaggle Blog: 10 articles\n",
            "  Microsoft Azure Blog: 10 articles\n",
            "  Official Microsoft Blog: 10 articles\n",
            "  Meta Engineering Blog: 9 articles\n",
            "  CloudTweaks: 5 articles\n",
            "  HuffPost Tech: 1 articles\n"
          ]
        }
      ],
      "source": [
        "# Save the collected data as JSON\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Create data directory if it doesn't exist\n",
        "os.makedirs('../data', exist_ok=True)\n",
        "\n",
        "# Generate filename with timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "filename = f\"../data/rss_articles_{timestamp}.json\"\n",
        "\n",
        "# Save to JSON\n",
        "with open(filename, 'w', encoding='utf-8') as f:\n",
        "    json.dump(all_articles, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ Saved {len(all_articles)} articles to {filename}\")\n",
        "\n",
        "# Also save a summary\n",
        "summary = {\n",
        "    'collection_date': datetime.now().isoformat(),\n",
        "    'total_articles': len(all_articles),\n",
        "    'sources': df['source'].value_counts().to_dict(),\n",
        "    'filename': filename\n",
        "}\n",
        "\n",
        "summary_filename = f\"../data/collection_summary_{timestamp}.json\"\n",
        "with open(summary_filename, 'w', encoding='utf-8') as f:\n",
        "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ Saved collection summary to {summary_filename}\")\n",
        "print(f\"\\nArticles by source:\")\n",
        "for source, count in summary['sources'].items():\n",
        "    print(f\"  {source}: {count} articles\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
